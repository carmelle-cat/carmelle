{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CC Final Project Part 2 - Classification",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_Dn9rzyiqxi"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGLKx-6qiz-_"
      },
      "source": [
        "Upload the labels.csv and processed_counts.csv files to colab or your local workspace.\n",
        "\n",
        "**Copied from Part 1:**\n",
        "This data associates a cell barcode, such as \"AAAGCCTGGCTAAC-1\", to a certain cell type label, such as \"CD14+ Monocyte\". For each cell barcode, there are also log RNA seq counts of 765 different genes, such as HES4.\n",
        "\n",
        "label.csv stores the association between a cell barcode and a cell type label.\n",
        "\n",
        "processed_counts.csv stores the normalized log read counts for each cell, where each row represents a single cell, and each column represents a gene."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPKnanEVFI0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86fd26f8-a2d5-4744-f2b6-8abb654b2b45"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WelsjSzviy4m"
      },
      "source": [
        "labels_pd = pd.read_csv(\"/content/drive/MyDrive/labels.csv\")\n",
        "counts_pd = pd.read_csv(\"/content/drive/MyDrive/processed_counts.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIX8kcTXi7EV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "outputId": "099b78b3-5496-4acc-be85-b5580cf207ba"
      },
      "source": [
        "labels_pd.index = labels_pd['index']\n",
        "labels_pd.drop(\"index\", axis=1, inplace=True)\n",
        "counts_pd.index = counts_pd['Unnamed: 0']\n",
        "counts_pd.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
        "\n",
        "df = counts_pd.merge(labels_pd, left_index=True, right_index=True).dropna()\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HES4</th>\n",
              "      <th>TNFRSF4</th>\n",
              "      <th>SSU72</th>\n",
              "      <th>PARK7</th>\n",
              "      <th>RBP7</th>\n",
              "      <th>SRM</th>\n",
              "      <th>MAD2L2</th>\n",
              "      <th>AGTRAP</th>\n",
              "      <th>TNFRSF1B</th>\n",
              "      <th>EFHD2</th>\n",
              "      <th>NECAP2</th>\n",
              "      <th>HP1BP3</th>\n",
              "      <th>C1QA</th>\n",
              "      <th>C1QB</th>\n",
              "      <th>HNRNPR</th>\n",
              "      <th>GALE</th>\n",
              "      <th>STMN1</th>\n",
              "      <th>CD52</th>\n",
              "      <th>FGR</th>\n",
              "      <th>ATPIF1</th>\n",
              "      <th>SESN2</th>\n",
              "      <th>EIF3I</th>\n",
              "      <th>LCK</th>\n",
              "      <th>MARCKSL1</th>\n",
              "      <th>SFPQ</th>\n",
              "      <th>PSMB2</th>\n",
              "      <th>MEAF6</th>\n",
              "      <th>NDUFS5</th>\n",
              "      <th>CAP1</th>\n",
              "      <th>SMAP2</th>\n",
              "      <th>C1orf228</th>\n",
              "      <th>PRDX1</th>\n",
              "      <th>TMEM69</th>\n",
              "      <th>SCP2</th>\n",
              "      <th>MAGOH</th>\n",
              "      <th>JAK1</th>\n",
              "      <th>CCBL2</th>\n",
              "      <th>GBP2</th>\n",
              "      <th>CD53</th>\n",
              "      <th>DENND2D</th>\n",
              "      <th>...</th>\n",
              "      <th>ZNF600</th>\n",
              "      <th>ZNF524</th>\n",
              "      <th>CTD-3138B18.5</th>\n",
              "      <th>ATP6V1E1</th>\n",
              "      <th>BID</th>\n",
              "      <th>MRPL40</th>\n",
              "      <th>UFD1L</th>\n",
              "      <th>COMT</th>\n",
              "      <th>DGCR6L</th>\n",
              "      <th>SDF2L1</th>\n",
              "      <th>IGLL5</th>\n",
              "      <th>IGLL1</th>\n",
              "      <th>CHCHD10</th>\n",
              "      <th>SMARCB1</th>\n",
              "      <th>MIF</th>\n",
              "      <th>ASCC2</th>\n",
              "      <th>PIK3IP1</th>\n",
              "      <th>HMOX1</th>\n",
              "      <th>EIF3D</th>\n",
              "      <th>IL2RB</th>\n",
              "      <th>LGALS2</th>\n",
              "      <th>EIF3L</th>\n",
              "      <th>ADSL</th>\n",
              "      <th>RBX1</th>\n",
              "      <th>TTC38</th>\n",
              "      <th>TYMP</th>\n",
              "      <th>CCT8</th>\n",
              "      <th>SOD1</th>\n",
              "      <th>PAXBP1</th>\n",
              "      <th>ATP5O</th>\n",
              "      <th>MRPS6</th>\n",
              "      <th>TTC3</th>\n",
              "      <th>U2AF1</th>\n",
              "      <th>CSTB</th>\n",
              "      <th>SUMO3</th>\n",
              "      <th>ITGB2</th>\n",
              "      <th>S100B</th>\n",
              "      <th>PRMT2</th>\n",
              "      <th>MT-ND3</th>\n",
              "      <th>bulk_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AAAGCCTGGCTAAC-1</th>\n",
              "      <td>-0.326</td>\n",
              "      <td>-0.191</td>\n",
              "      <td>-0.728</td>\n",
              "      <td>-0.301</td>\n",
              "      <td>3.386</td>\n",
              "      <td>-0.531</td>\n",
              "      <td>2.016</td>\n",
              "      <td>3.377</td>\n",
              "      <td>4.841</td>\n",
              "      <td>-0.525</td>\n",
              "      <td>-0.525</td>\n",
              "      <td>1.804</td>\n",
              "      <td>0.578</td>\n",
              "      <td>-0.198</td>\n",
              "      <td>1.266</td>\n",
              "      <td>-0.192</td>\n",
              "      <td>-0.307</td>\n",
              "      <td>0.048</td>\n",
              "      <td>-0.606</td>\n",
              "      <td>0.478</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.864</td>\n",
              "      <td>-0.534</td>\n",
              "      <td>-0.504</td>\n",
              "      <td>-0.509</td>\n",
              "      <td>-0.727</td>\n",
              "      <td>-0.646</td>\n",
              "      <td>0.336</td>\n",
              "      <td>-0.017</td>\n",
              "      <td>4.381</td>\n",
              "      <td>-0.251</td>\n",
              "      <td>0.235</td>\n",
              "      <td>-0.252</td>\n",
              "      <td>-0.701</td>\n",
              "      <td>-0.537</td>\n",
              "      <td>-0.684</td>\n",
              "      <td>-0.244</td>\n",
              "      <td>-0.421</td>\n",
              "      <td>0.575</td>\n",
              "      <td>-0.375</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.109</td>\n",
              "      <td>-0.402</td>\n",
              "      <td>-0.122</td>\n",
              "      <td>-0.583</td>\n",
              "      <td>-0.690</td>\n",
              "      <td>-0.487</td>\n",
              "      <td>-0.582</td>\n",
              "      <td>-0.630</td>\n",
              "      <td>-0.507</td>\n",
              "      <td>0.697</td>\n",
              "      <td>-0.133</td>\n",
              "      <td>-0.062</td>\n",
              "      <td>1.777</td>\n",
              "      <td>0.948</td>\n",
              "      <td>0.436</td>\n",
              "      <td>-0.345</td>\n",
              "      <td>-0.418</td>\n",
              "      <td>0.652</td>\n",
              "      <td>0.351</td>\n",
              "      <td>-0.196</td>\n",
              "      <td>-0.413</td>\n",
              "      <td>-0.323</td>\n",
              "      <td>-0.491</td>\n",
              "      <td>-0.719</td>\n",
              "      <td>-0.205</td>\n",
              "      <td>-0.092</td>\n",
              "      <td>-0.694</td>\n",
              "      <td>-0.070</td>\n",
              "      <td>-0.116</td>\n",
              "      <td>-0.146</td>\n",
              "      <td>-0.532</td>\n",
              "      <td>-0.341</td>\n",
              "      <td>0.303</td>\n",
              "      <td>1.404</td>\n",
              "      <td>4.294</td>\n",
              "      <td>0.519</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.636</td>\n",
              "      <td>4.011</td>\n",
              "      <td>CD14+ Monocyte</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AAATTCGATGCACA-1</th>\n",
              "      <td>1.171</td>\n",
              "      <td>-0.191</td>\n",
              "      <td>0.795</td>\n",
              "      <td>-1.200</td>\n",
              "      <td>-0.174</td>\n",
              "      <td>-0.531</td>\n",
              "      <td>1.889</td>\n",
              "      <td>-0.486</td>\n",
              "      <td>-0.459</td>\n",
              "      <td>-0.525</td>\n",
              "      <td>1.287</td>\n",
              "      <td>-0.420</td>\n",
              "      <td>0.954</td>\n",
              "      <td>2.367</td>\n",
              "      <td>1.170</td>\n",
              "      <td>-0.192</td>\n",
              "      <td>-0.307</td>\n",
              "      <td>0.266</td>\n",
              "      <td>0.629</td>\n",
              "      <td>-0.802</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.864</td>\n",
              "      <td>-0.534</td>\n",
              "      <td>0.873</td>\n",
              "      <td>-0.509</td>\n",
              "      <td>0.645</td>\n",
              "      <td>-0.646</td>\n",
              "      <td>0.274</td>\n",
              "      <td>0.856</td>\n",
              "      <td>1.845</td>\n",
              "      <td>-0.251</td>\n",
              "      <td>-0.796</td>\n",
              "      <td>-0.252</td>\n",
              "      <td>-0.701</td>\n",
              "      <td>1.581</td>\n",
              "      <td>-0.684</td>\n",
              "      <td>-0.244</td>\n",
              "      <td>-0.421</td>\n",
              "      <td>-0.282</td>\n",
              "      <td>-0.375</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.109</td>\n",
              "      <td>-0.402</td>\n",
              "      <td>-0.122</td>\n",
              "      <td>-0.583</td>\n",
              "      <td>2.992</td>\n",
              "      <td>1.327</td>\n",
              "      <td>-0.582</td>\n",
              "      <td>0.991</td>\n",
              "      <td>-0.507</td>\n",
              "      <td>0.636</td>\n",
              "      <td>-0.133</td>\n",
              "      <td>-0.062</td>\n",
              "      <td>-0.687</td>\n",
              "      <td>-0.497</td>\n",
              "      <td>0.373</td>\n",
              "      <td>-0.345</td>\n",
              "      <td>-0.418</td>\n",
              "      <td>-0.366</td>\n",
              "      <td>1.496</td>\n",
              "      <td>-0.196</td>\n",
              "      <td>-0.413</td>\n",
              "      <td>0.478</td>\n",
              "      <td>-0.491</td>\n",
              "      <td>-0.719</td>\n",
              "      <td>-0.205</td>\n",
              "      <td>1.089</td>\n",
              "      <td>-0.694</td>\n",
              "      <td>-0.120</td>\n",
              "      <td>-0.116</td>\n",
              "      <td>-1.136</td>\n",
              "      <td>-0.532</td>\n",
              "      <td>-0.341</td>\n",
              "      <td>-0.905</td>\n",
              "      <td>2.849</td>\n",
              "      <td>-0.585</td>\n",
              "      <td>1.172</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>2.630</td>\n",
              "      <td>-0.490</td>\n",
              "      <td>Dendritic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AACACGTGGTCTTT-1</th>\n",
              "      <td>-0.326</td>\n",
              "      <td>-0.191</td>\n",
              "      <td>0.483</td>\n",
              "      <td>-1.200</td>\n",
              "      <td>-0.174</td>\n",
              "      <td>-0.531</td>\n",
              "      <td>-0.451</td>\n",
              "      <td>0.971</td>\n",
              "      <td>-0.459</td>\n",
              "      <td>2.286</td>\n",
              "      <td>-0.525</td>\n",
              "      <td>1.258</td>\n",
              "      <td>-0.310</td>\n",
              "      <td>-0.198</td>\n",
              "      <td>-0.602</td>\n",
              "      <td>-0.192</td>\n",
              "      <td>-0.307</td>\n",
              "      <td>-0.462</td>\n",
              "      <td>1.358</td>\n",
              "      <td>-0.802</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>0.205</td>\n",
              "      <td>-0.534</td>\n",
              "      <td>-0.504</td>\n",
              "      <td>-0.509</td>\n",
              "      <td>0.364</td>\n",
              "      <td>-0.646</td>\n",
              "      <td>-0.881</td>\n",
              "      <td>-0.256</td>\n",
              "      <td>-0.445</td>\n",
              "      <td>-0.251</td>\n",
              "      <td>-0.796</td>\n",
              "      <td>-0.252</td>\n",
              "      <td>0.480</td>\n",
              "      <td>2.831</td>\n",
              "      <td>1.528</td>\n",
              "      <td>-0.244</td>\n",
              "      <td>0.816</td>\n",
              "      <td>-0.440</td>\n",
              "      <td>1.583</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.109</td>\n",
              "      <td>-0.402</td>\n",
              "      <td>-0.122</td>\n",
              "      <td>-0.583</td>\n",
              "      <td>-0.690</td>\n",
              "      <td>-0.487</td>\n",
              "      <td>-0.582</td>\n",
              "      <td>-0.630</td>\n",
              "      <td>-0.507</td>\n",
              "      <td>-0.502</td>\n",
              "      <td>-0.133</td>\n",
              "      <td>-0.062</td>\n",
              "      <td>-0.687</td>\n",
              "      <td>-0.497</td>\n",
              "      <td>-0.782</td>\n",
              "      <td>-0.345</td>\n",
              "      <td>-0.418</td>\n",
              "      <td>-0.366</td>\n",
              "      <td>0.037</td>\n",
              "      <td>5.397</td>\n",
              "      <td>-0.413</td>\n",
              "      <td>0.131</td>\n",
              "      <td>1.310</td>\n",
              "      <td>-0.719</td>\n",
              "      <td>-0.205</td>\n",
              "      <td>-0.733</td>\n",
              "      <td>1.747</td>\n",
              "      <td>0.428</td>\n",
              "      <td>-0.116</td>\n",
              "      <td>-1.136</td>\n",
              "      <td>2.606</td>\n",
              "      <td>-0.341</td>\n",
              "      <td>-0.905</td>\n",
              "      <td>-0.455</td>\n",
              "      <td>-0.585</td>\n",
              "      <td>0.722</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>0.663</td>\n",
              "      <td>-0.490</td>\n",
              "      <td>CD56+ NK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AAGTGCACGTGCTA-1</th>\n",
              "      <td>-0.326</td>\n",
              "      <td>-0.191</td>\n",
              "      <td>1.134</td>\n",
              "      <td>-0.157</td>\n",
              "      <td>-0.174</td>\n",
              "      <td>-0.531</td>\n",
              "      <td>-0.451</td>\n",
              "      <td>-0.486</td>\n",
              "      <td>-0.459</td>\n",
              "      <td>-0.525</td>\n",
              "      <td>-0.525</td>\n",
              "      <td>9.900</td>\n",
              "      <td>-0.310</td>\n",
              "      <td>-0.198</td>\n",
              "      <td>1.565</td>\n",
              "      <td>-0.192</td>\n",
              "      <td>2.270</td>\n",
              "      <td>1.258</td>\n",
              "      <td>-0.606</td>\n",
              "      <td>-0.802</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.864</td>\n",
              "      <td>0.741</td>\n",
              "      <td>-0.504</td>\n",
              "      <td>2.193</td>\n",
              "      <td>2.630</td>\n",
              "      <td>1.627</td>\n",
              "      <td>-0.881</td>\n",
              "      <td>-0.990</td>\n",
              "      <td>-0.445</td>\n",
              "      <td>-0.251</td>\n",
              "      <td>-0.796</td>\n",
              "      <td>-0.252</td>\n",
              "      <td>1.114</td>\n",
              "      <td>-0.537</td>\n",
              "      <td>-0.684</td>\n",
              "      <td>-0.244</td>\n",
              "      <td>1.481</td>\n",
              "      <td>2.728</td>\n",
              "      <td>-0.375</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.109</td>\n",
              "      <td>-0.402</td>\n",
              "      <td>-0.122</td>\n",
              "      <td>-0.583</td>\n",
              "      <td>-0.690</td>\n",
              "      <td>-0.487</td>\n",
              "      <td>-0.582</td>\n",
              "      <td>-0.630</td>\n",
              "      <td>-0.507</td>\n",
              "      <td>-0.502</td>\n",
              "      <td>-0.133</td>\n",
              "      <td>-0.062</td>\n",
              "      <td>-0.687</td>\n",
              "      <td>-0.497</td>\n",
              "      <td>-0.782</td>\n",
              "      <td>-0.345</td>\n",
              "      <td>-0.418</td>\n",
              "      <td>-0.366</td>\n",
              "      <td>2.036</td>\n",
              "      <td>-0.196</td>\n",
              "      <td>-0.413</td>\n",
              "      <td>-0.180</td>\n",
              "      <td>-0.491</td>\n",
              "      <td>-0.719</td>\n",
              "      <td>-0.205</td>\n",
              "      <td>-0.733</td>\n",
              "      <td>-0.694</td>\n",
              "      <td>1.221</td>\n",
              "      <td>-0.116</td>\n",
              "      <td>1.161</td>\n",
              "      <td>-0.532</td>\n",
              "      <td>-0.341</td>\n",
              "      <td>-0.905</td>\n",
              "      <td>-0.119</td>\n",
              "      <td>-0.585</td>\n",
              "      <td>0.766</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.636</td>\n",
              "      <td>-0.490</td>\n",
              "      <td>CD4+/CD25 T Reg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ACACGAACGGAGTG-1</th>\n",
              "      <td>-0.326</td>\n",
              "      <td>-0.191</td>\n",
              "      <td>-0.728</td>\n",
              "      <td>-0.607</td>\n",
              "      <td>-0.174</td>\n",
              "      <td>-0.531</td>\n",
              "      <td>-0.451</td>\n",
              "      <td>0.787</td>\n",
              "      <td>-0.459</td>\n",
              "      <td>1.932</td>\n",
              "      <td>-0.525</td>\n",
              "      <td>1.046</td>\n",
              "      <td>-0.310</td>\n",
              "      <td>-0.198</td>\n",
              "      <td>0.630</td>\n",
              "      <td>-0.192</td>\n",
              "      <td>-0.307</td>\n",
              "      <td>-0.546</td>\n",
              "      <td>1.110</td>\n",
              "      <td>1.730</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>1.005</td>\n",
              "      <td>-0.534</td>\n",
              "      <td>-0.504</td>\n",
              "      <td>-0.509</td>\n",
              "      <td>-0.727</td>\n",
              "      <td>-0.646</td>\n",
              "      <td>-0.881</td>\n",
              "      <td>0.293</td>\n",
              "      <td>-0.445</td>\n",
              "      <td>-0.251</td>\n",
              "      <td>-0.796</td>\n",
              "      <td>-0.252</td>\n",
              "      <td>1.363</td>\n",
              "      <td>2.407</td>\n",
              "      <td>0.283</td>\n",
              "      <td>-0.244</td>\n",
              "      <td>-0.421</td>\n",
              "      <td>-0.518</td>\n",
              "      <td>-0.375</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.109</td>\n",
              "      <td>-0.402</td>\n",
              "      <td>-0.122</td>\n",
              "      <td>-0.583</td>\n",
              "      <td>-0.690</td>\n",
              "      <td>-0.487</td>\n",
              "      <td>-0.582</td>\n",
              "      <td>-0.630</td>\n",
              "      <td>-0.507</td>\n",
              "      <td>-0.502</td>\n",
              "      <td>-0.133</td>\n",
              "      <td>-0.062</td>\n",
              "      <td>-0.687</td>\n",
              "      <td>-0.497</td>\n",
              "      <td>0.824</td>\n",
              "      <td>-0.345</td>\n",
              "      <td>-0.418</td>\n",
              "      <td>0.306</td>\n",
              "      <td>-0.926</td>\n",
              "      <td>-0.196</td>\n",
              "      <td>3.847</td>\n",
              "      <td>1.138</td>\n",
              "      <td>-0.491</td>\n",
              "      <td>0.213</td>\n",
              "      <td>-0.205</td>\n",
              "      <td>-0.310</td>\n",
              "      <td>-0.694</td>\n",
              "      <td>-1.048</td>\n",
              "      <td>-0.116</td>\n",
              "      <td>-1.136</td>\n",
              "      <td>0.839</td>\n",
              "      <td>1.679</td>\n",
              "      <td>-0.108</td>\n",
              "      <td>-0.534</td>\n",
              "      <td>-0.585</td>\n",
              "      <td>-0.007</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.636</td>\n",
              "      <td>-0.490</td>\n",
              "      <td>Dendritic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TGGCACCTCCAACA-8</th>\n",
              "      <td>-0.326</td>\n",
              "      <td>-0.191</td>\n",
              "      <td>0.372</td>\n",
              "      <td>-0.584</td>\n",
              "      <td>-0.174</td>\n",
              "      <td>0.509</td>\n",
              "      <td>-0.451</td>\n",
              "      <td>2.160</td>\n",
              "      <td>-0.459</td>\n",
              "      <td>0.751</td>\n",
              "      <td>-0.525</td>\n",
              "      <td>-0.420</td>\n",
              "      <td>-0.310</td>\n",
              "      <td>0.265</td>\n",
              "      <td>-0.602</td>\n",
              "      <td>-0.192</td>\n",
              "      <td>-0.307</td>\n",
              "      <td>-1.127</td>\n",
              "      <td>-0.606</td>\n",
              "      <td>-0.802</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>0.107</td>\n",
              "      <td>-0.534</td>\n",
              "      <td>2.478</td>\n",
              "      <td>-0.509</td>\n",
              "      <td>0.264</td>\n",
              "      <td>0.696</td>\n",
              "      <td>-0.881</td>\n",
              "      <td>1.676</td>\n",
              "      <td>-0.445</td>\n",
              "      <td>-0.251</td>\n",
              "      <td>-0.796</td>\n",
              "      <td>-0.252</td>\n",
              "      <td>-0.701</td>\n",
              "      <td>-0.537</td>\n",
              "      <td>1.324</td>\n",
              "      <td>-0.244</td>\n",
              "      <td>-0.421</td>\n",
              "      <td>-0.497</td>\n",
              "      <td>-0.375</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.109</td>\n",
              "      <td>-0.402</td>\n",
              "      <td>-0.122</td>\n",
              "      <td>-0.583</td>\n",
              "      <td>0.639</td>\n",
              "      <td>-0.487</td>\n",
              "      <td>-0.582</td>\n",
              "      <td>-0.630</td>\n",
              "      <td>-0.507</td>\n",
              "      <td>0.319</td>\n",
              "      <td>-0.133</td>\n",
              "      <td>-0.062</td>\n",
              "      <td>1.001</td>\n",
              "      <td>0.493</td>\n",
              "      <td>0.886</td>\n",
              "      <td>-0.345</td>\n",
              "      <td>-0.418</td>\n",
              "      <td>-0.366</td>\n",
              "      <td>0.823</td>\n",
              "      <td>-0.196</td>\n",
              "      <td>1.247</td>\n",
              "      <td>0.618</td>\n",
              "      <td>-0.491</td>\n",
              "      <td>-0.719</td>\n",
              "      <td>-0.205</td>\n",
              "      <td>0.144</td>\n",
              "      <td>-0.694</td>\n",
              "      <td>-0.378</td>\n",
              "      <td>-0.116</td>\n",
              "      <td>1.576</td>\n",
              "      <td>-0.532</td>\n",
              "      <td>1.758</td>\n",
              "      <td>1.578</td>\n",
              "      <td>0.055</td>\n",
              "      <td>-0.585</td>\n",
              "      <td>0.561</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>0.543</td>\n",
              "      <td>2.593</td>\n",
              "      <td>Dendritic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TGTGAGTGCTTTAC-8</th>\n",
              "      <td>3.166</td>\n",
              "      <td>-0.191</td>\n",
              "      <td>-0.728</td>\n",
              "      <td>-1.200</td>\n",
              "      <td>-0.174</td>\n",
              "      <td>-0.531</td>\n",
              "      <td>-0.451</td>\n",
              "      <td>-0.486</td>\n",
              "      <td>-0.459</td>\n",
              "      <td>1.536</td>\n",
              "      <td>-0.525</td>\n",
              "      <td>2.040</td>\n",
              "      <td>-0.310</td>\n",
              "      <td>2.793</td>\n",
              "      <td>-0.602</td>\n",
              "      <td>-0.192</td>\n",
              "      <td>-0.307</td>\n",
              "      <td>-0.477</td>\n",
              "      <td>0.834</td>\n",
              "      <td>0.614</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>0.704</td>\n",
              "      <td>-0.534</td>\n",
              "      <td>-0.504</td>\n",
              "      <td>-0.509</td>\n",
              "      <td>-0.727</td>\n",
              "      <td>-0.646</td>\n",
              "      <td>0.465</td>\n",
              "      <td>1.163</td>\n",
              "      <td>2.225</td>\n",
              "      <td>-0.251</td>\n",
              "      <td>1.486</td>\n",
              "      <td>-0.252</td>\n",
              "      <td>-0.701</td>\n",
              "      <td>-0.537</td>\n",
              "      <td>-0.684</td>\n",
              "      <td>-0.244</td>\n",
              "      <td>3.206</td>\n",
              "      <td>2.553</td>\n",
              "      <td>-0.375</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.109</td>\n",
              "      <td>-0.402</td>\n",
              "      <td>-0.122</td>\n",
              "      <td>-0.583</td>\n",
              "      <td>-0.690</td>\n",
              "      <td>-0.487</td>\n",
              "      <td>-0.582</td>\n",
              "      <td>1.260</td>\n",
              "      <td>-0.507</td>\n",
              "      <td>0.825</td>\n",
              "      <td>-0.133</td>\n",
              "      <td>-0.062</td>\n",
              "      <td>0.676</td>\n",
              "      <td>-0.497</td>\n",
              "      <td>0.565</td>\n",
              "      <td>-0.345</td>\n",
              "      <td>2.266</td>\n",
              "      <td>-0.366</td>\n",
              "      <td>-0.926</td>\n",
              "      <td>-0.196</td>\n",
              "      <td>-0.413</td>\n",
              "      <td>1.746</td>\n",
              "      <td>-0.491</td>\n",
              "      <td>-0.719</td>\n",
              "      <td>-0.205</td>\n",
              "      <td>2.100</td>\n",
              "      <td>-0.694</td>\n",
              "      <td>0.034</td>\n",
              "      <td>-0.116</td>\n",
              "      <td>-1.136</td>\n",
              "      <td>-0.532</td>\n",
              "      <td>-0.341</td>\n",
              "      <td>0.432</td>\n",
              "      <td>0.753</td>\n",
              "      <td>-0.585</td>\n",
              "      <td>-0.171</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>1.268</td>\n",
              "      <td>-0.490</td>\n",
              "      <td>Dendritic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TGTTACTGGCGATT-8</th>\n",
              "      <td>-0.326</td>\n",
              "      <td>-0.191</td>\n",
              "      <td>-0.728</td>\n",
              "      <td>-1.200</td>\n",
              "      <td>-0.174</td>\n",
              "      <td>1.784</td>\n",
              "      <td>-0.451</td>\n",
              "      <td>-0.486</td>\n",
              "      <td>-0.459</td>\n",
              "      <td>-0.525</td>\n",
              "      <td>0.931</td>\n",
              "      <td>-0.420</td>\n",
              "      <td>-0.310</td>\n",
              "      <td>-0.198</td>\n",
              "      <td>-0.602</td>\n",
              "      <td>-0.192</td>\n",
              "      <td>-0.307</td>\n",
              "      <td>-0.008</td>\n",
              "      <td>-0.606</td>\n",
              "      <td>1.150</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>1.297</td>\n",
              "      <td>2.816</td>\n",
              "      <td>-0.504</td>\n",
              "      <td>-0.509</td>\n",
              "      <td>0.376</td>\n",
              "      <td>-0.646</td>\n",
              "      <td>-0.881</td>\n",
              "      <td>0.494</td>\n",
              "      <td>3.235</td>\n",
              "      <td>-0.251</td>\n",
              "      <td>-0.010</td>\n",
              "      <td>-0.252</td>\n",
              "      <td>0.492</td>\n",
              "      <td>-0.537</td>\n",
              "      <td>1.551</td>\n",
              "      <td>-0.244</td>\n",
              "      <td>-0.421</td>\n",
              "      <td>0.188</td>\n",
              "      <td>-0.375</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.109</td>\n",
              "      <td>-0.402</td>\n",
              "      <td>-0.122</td>\n",
              "      <td>-0.583</td>\n",
              "      <td>-0.690</td>\n",
              "      <td>-0.487</td>\n",
              "      <td>-0.582</td>\n",
              "      <td>-0.630</td>\n",
              "      <td>1.261</td>\n",
              "      <td>0.412</td>\n",
              "      <td>-0.133</td>\n",
              "      <td>-0.062</td>\n",
              "      <td>0.252</td>\n",
              "      <td>-0.497</td>\n",
              "      <td>0.146</td>\n",
              "      <td>-0.345</td>\n",
              "      <td>-0.418</td>\n",
              "      <td>-0.366</td>\n",
              "      <td>0.047</td>\n",
              "      <td>-0.196</td>\n",
              "      <td>-0.413</td>\n",
              "      <td>-0.535</td>\n",
              "      <td>-0.491</td>\n",
              "      <td>-0.719</td>\n",
              "      <td>-0.205</td>\n",
              "      <td>-0.733</td>\n",
              "      <td>1.772</td>\n",
              "      <td>3.425</td>\n",
              "      <td>-0.116</td>\n",
              "      <td>-0.381</td>\n",
              "      <td>-0.532</td>\n",
              "      <td>-0.341</td>\n",
              "      <td>1.858</td>\n",
              "      <td>0.814</td>\n",
              "      <td>-0.585</td>\n",
              "      <td>0.152</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.636</td>\n",
              "      <td>1.226</td>\n",
              "      <td>CD4+/CD25 T Reg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TTCAGTACCGGGAA-8</th>\n",
              "      <td>-0.326</td>\n",
              "      <td>-0.191</td>\n",
              "      <td>-0.728</td>\n",
              "      <td>-0.386</td>\n",
              "      <td>-0.174</td>\n",
              "      <td>-0.531</td>\n",
              "      <td>-0.451</td>\n",
              "      <td>-0.486</td>\n",
              "      <td>-0.459</td>\n",
              "      <td>-0.525</td>\n",
              "      <td>-0.525</td>\n",
              "      <td>-0.420</td>\n",
              "      <td>-0.310</td>\n",
              "      <td>-0.198</td>\n",
              "      <td>1.090</td>\n",
              "      <td>-0.192</td>\n",
              "      <td>-0.307</td>\n",
              "      <td>1.800</td>\n",
              "      <td>-0.606</td>\n",
              "      <td>-0.802</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>0.419</td>\n",
              "      <td>0.461</td>\n",
              "      <td>-0.504</td>\n",
              "      <td>-0.509</td>\n",
              "      <td>-0.727</td>\n",
              "      <td>1.129</td>\n",
              "      <td>0.221</td>\n",
              "      <td>0.773</td>\n",
              "      <td>3.927</td>\n",
              "      <td>-0.251</td>\n",
              "      <td>0.138</td>\n",
              "      <td>-0.252</td>\n",
              "      <td>0.716</td>\n",
              "      <td>-0.537</td>\n",
              "      <td>-0.684</td>\n",
              "      <td>7.869</td>\n",
              "      <td>-0.421</td>\n",
              "      <td>2.637</td>\n",
              "      <td>-0.375</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.109</td>\n",
              "      <td>-0.402</td>\n",
              "      <td>-0.122</td>\n",
              "      <td>1.198</td>\n",
              "      <td>-0.690</td>\n",
              "      <td>-0.487</td>\n",
              "      <td>-0.582</td>\n",
              "      <td>-0.630</td>\n",
              "      <td>-0.507</td>\n",
              "      <td>-0.502</td>\n",
              "      <td>-0.133</td>\n",
              "      <td>-0.062</td>\n",
              "      <td>0.429</td>\n",
              "      <td>-0.497</td>\n",
              "      <td>0.321</td>\n",
              "      <td>-0.345</td>\n",
              "      <td>-0.418</td>\n",
              "      <td>-0.366</td>\n",
              "      <td>0.230</td>\n",
              "      <td>-0.196</td>\n",
              "      <td>-0.413</td>\n",
              "      <td>-0.407</td>\n",
              "      <td>-0.491</td>\n",
              "      <td>-0.719</td>\n",
              "      <td>-0.205</td>\n",
              "      <td>-0.733</td>\n",
              "      <td>-0.694</td>\n",
              "      <td>-0.162</td>\n",
              "      <td>-0.116</td>\n",
              "      <td>-1.136</td>\n",
              "      <td>-0.532</td>\n",
              "      <td>-0.341</td>\n",
              "      <td>2.378</td>\n",
              "      <td>0.420</td>\n",
              "      <td>0.888</td>\n",
              "      <td>-0.326</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.636</td>\n",
              "      <td>-0.490</td>\n",
              "      <td>CD19+ B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TTGAGGTGGAGAGC-8</th>\n",
              "      <td>-0.326</td>\n",
              "      <td>-0.191</td>\n",
              "      <td>0.148</td>\n",
              "      <td>0.762</td>\n",
              "      <td>-0.174</td>\n",
              "      <td>0.298</td>\n",
              "      <td>-0.451</td>\n",
              "      <td>-0.486</td>\n",
              "      <td>0.505</td>\n",
              "      <td>-0.525</td>\n",
              "      <td>-0.525</td>\n",
              "      <td>0.794</td>\n",
              "      <td>0.175</td>\n",
              "      <td>0.171</td>\n",
              "      <td>-0.602</td>\n",
              "      <td>-0.192</td>\n",
              "      <td>-0.307</td>\n",
              "      <td>-0.326</td>\n",
              "      <td>-0.606</td>\n",
              "      <td>0.595</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.091</td>\n",
              "      <td>-0.534</td>\n",
              "      <td>-0.504</td>\n",
              "      <td>-0.509</td>\n",
              "      <td>0.062</td>\n",
              "      <td>-0.646</td>\n",
              "      <td>1.112</td>\n",
              "      <td>0.072</td>\n",
              "      <td>-0.445</td>\n",
              "      <td>-0.251</td>\n",
              "      <td>-0.233</td>\n",
              "      <td>-0.252</td>\n",
              "      <td>1.007</td>\n",
              "      <td>-0.537</td>\n",
              "      <td>0.116</td>\n",
              "      <td>-0.244</td>\n",
              "      <td>-0.421</td>\n",
              "      <td>-0.165</td>\n",
              "      <td>-0.375</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.109</td>\n",
              "      <td>2.453</td>\n",
              "      <td>-0.122</td>\n",
              "      <td>-0.583</td>\n",
              "      <td>-0.160</td>\n",
              "      <td>-0.487</td>\n",
              "      <td>-0.582</td>\n",
              "      <td>0.302</td>\n",
              "      <td>-0.507</td>\n",
              "      <td>-0.502</td>\n",
              "      <td>-0.133</td>\n",
              "      <td>-0.062</td>\n",
              "      <td>-0.687</td>\n",
              "      <td>0.291</td>\n",
              "      <td>-0.782</td>\n",
              "      <td>-0.345</td>\n",
              "      <td>-0.418</td>\n",
              "      <td>-0.366</td>\n",
              "      <td>0.467</td>\n",
              "      <td>-0.196</td>\n",
              "      <td>0.469</td>\n",
              "      <td>-0.729</td>\n",
              "      <td>-0.491</td>\n",
              "      <td>0.823</td>\n",
              "      <td>-0.205</td>\n",
              "      <td>-0.733</td>\n",
              "      <td>-0.694</td>\n",
              "      <td>-0.514</td>\n",
              "      <td>-0.116</td>\n",
              "      <td>-1.136</td>\n",
              "      <td>-0.532</td>\n",
              "      <td>-0.341</td>\n",
              "      <td>1.073</td>\n",
              "      <td>-0.628</td>\n",
              "      <td>-0.585</td>\n",
              "      <td>0.239</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.636</td>\n",
              "      <td>-0.490</td>\n",
              "      <td>Dendritic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>700 rows Ã— 766 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   HES4  TNFRSF4  SSU72  ...  PRMT2  MT-ND3      bulk_labels\n",
              "AAAGCCTGGCTAAC-1 -0.326   -0.191 -0.728  ... -0.636   4.011   CD14+ Monocyte\n",
              "AAATTCGATGCACA-1  1.171   -0.191  0.795  ...  2.630  -0.490        Dendritic\n",
              "AACACGTGGTCTTT-1 -0.326   -0.191  0.483  ...  0.663  -0.490         CD56+ NK\n",
              "AAGTGCACGTGCTA-1 -0.326   -0.191  1.134  ... -0.636  -0.490  CD4+/CD25 T Reg\n",
              "ACACGAACGGAGTG-1 -0.326   -0.191 -0.728  ... -0.636  -0.490        Dendritic\n",
              "...                 ...      ...    ...  ...    ...     ...              ...\n",
              "TGGCACCTCCAACA-8 -0.326   -0.191  0.372  ...  0.543   2.593        Dendritic\n",
              "TGTGAGTGCTTTAC-8  3.166   -0.191 -0.728  ...  1.268  -0.490        Dendritic\n",
              "TGTTACTGGCGATT-8 -0.326   -0.191 -0.728  ... -0.636   1.226  CD4+/CD25 T Reg\n",
              "TTCAGTACCGGGAA-8 -0.326   -0.191 -0.728  ... -0.636  -0.490          CD19+ B\n",
              "TTGAGGTGGAGAGC-8 -0.326   -0.191  0.148  ... -0.636  -0.490        Dendritic\n",
              "\n",
              "[700 rows x 766 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUxSCyz7jBQf"
      },
      "source": [
        "One-hot encode the cell-type.\n",
        "\n",
        "Shuffle your data. Make sure your labels and the counts are shuffled together.\n",
        "\n",
        "Split into train and test sets (80:20 split)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDTqBhcA7V8t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d15bc77d-02f8-4a4b-8320-d4a6f3ee152e"
      },
      "source": [
        "categories = df['bulk_labels'].unique()\n",
        "print(categories)\n",
        "\n",
        "#one-hot encoding\n",
        "y = np.zeros((len(df), len(categories)))\n",
        "for i in range(len(df)):\n",
        "  cell_type = df.iloc[i]['bulk_labels']\n",
        "  pos = np.where(categories == cell_type)[0]\n",
        "  y[i, pos] = 1\n",
        "\n",
        "#remove label when processing input data\n",
        "X = df.drop('bulk_labels', axis=1).values\n",
        "\n",
        "#shufle and 80:20 split\n",
        "np.random.seed(100)\n",
        "permutation = np.random.permutation(len(X))\n",
        "X, y = X[permutation], y[permutation]\n",
        "\n",
        "X_train, y_train = X[:int(len(X)*0.8)], y[:int(len(y)*0.8)]\n",
        "X_test, y_test = X[int(len(X)*0.8):], y[int(len(y)*0.8):]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['CD14+ Monocyte' 'Dendritic' 'CD56+ NK' 'CD4+/CD25 T Reg' 'CD19+ B'\n",
            " 'CD8+ Cytotoxic T' 'CD4+/CD45RO+ Memory' 'CD8+/CD45RA+ Naive Cytotoxic'\n",
            " 'CD4+/CD45RA+/CD25- Naive T' 'CD34+']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "id": "l0Xrhu4LZNa9",
        "outputId": "673ad32c-56e2-41ff-a4c4-9f1070d7499b"
      },
      "source": [
        "#Visualize the One-hot encoded Prediction Labels\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(9,3), dpi=300)\n",
        "plt.imshow(y_train[:50])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8d3982d250>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2700x900 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHIg7i1k7U-G"
      },
      "source": [
        "Apply classification algorithms to the training data, tune on validation data (if present), and evaluate on test data.\n",
        "\n",
        "You can also apply classification downstream of last week's autoencoder latent space representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSioywwC_wov"
      },
      "source": [
        "import random\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDzEHMeH_Pzm"
      },
      "source": [
        "# take a random sample of the training data with replacement\n",
        "\n",
        "def training_sample(n):\n",
        "\n",
        "  cell_bc = [i for i in range(len(X_train))]\n",
        "  rand = random.choices(cell_bc, k=n)\n",
        "\n",
        "  mini_counts = [X_train[i] for i in rand]\n",
        "  mini_labels = [y_train[i] for i in rand]\n",
        "\n",
        "  return mini_counts, mini_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8mvigLP7Sej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74b02d4e-ab50-4eb8-e210-2fba97deead9"
      },
      "source": [
        "# Decision Tree with Bagging \n",
        "# Because we are taking the aggregate of the results/using a BAGGING approach,\n",
        "# we can just implement a very simple model (50% accuracy is good)\n",
        "\n",
        "predictions = []\n",
        "\n",
        "max_iter = 100\n",
        "\n",
        "i=0\n",
        "\n",
        "while len(predictions) < 15 or i != max_iter:\n",
        "  # take a random sample of the data with replacement\n",
        "  sample_X, sample_Y = training_sample(300)\n",
        "\n",
        "  # create a multiout regressor with a random forest classifier  \n",
        "  forest = DecisionTreeClassifier(criterion='entropy', max_depth=None)\n",
        "  multiout_regressor = MultiOutputRegressor(forest, n_jobs=5)\n",
        "\n",
        "  # train the classifier\n",
        "  multiout_regressor.fit(sample_X, sample_Y)\n",
        "\n",
        "  # test on the data\n",
        "  y_pred = multiout_regressor.predict(X_test)\n",
        "\n",
        "  accuracy = accuracy_score(y_test, y_pred)  \n",
        "\n",
        "  print('iter: ', i, ' accuracy: ', accuracy)\n",
        "  #if the accuracy of this model is above a certain threshold, keep this prediction:\n",
        "  if accuracy >= 0.6:\n",
        "    predictions.append(y_pred)\n",
        "\n",
        "  i += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter:  0  accuracy:  0.5642857142857143\n",
            "iter:  1  accuracy:  0.5642857142857143\n",
            "iter:  2  accuracy:  0.5071428571428571\n",
            "iter:  3  accuracy:  0.55\n",
            "iter:  4  accuracy:  0.5571428571428572\n",
            "iter:  5  accuracy:  0.5214285714285715\n",
            "iter:  6  accuracy:  0.6357142857142857\n",
            "iter:  7  accuracy:  0.5714285714285714\n",
            "iter:  8  accuracy:  0.5214285714285715\n",
            "iter:  9  accuracy:  0.6214285714285714\n",
            "iter:  10  accuracy:  0.5428571428571428\n",
            "iter:  11  accuracy:  0.4785714285714286\n",
            "iter:  12  accuracy:  0.5571428571428572\n",
            "iter:  13  accuracy:  0.55\n",
            "iter:  14  accuracy:  0.6285714285714286\n",
            "iter:  15  accuracy:  0.5428571428571428\n",
            "iter:  16  accuracy:  0.5142857142857142\n",
            "iter:  17  accuracy:  0.5928571428571429\n",
            "iter:  18  accuracy:  0.5071428571428571\n",
            "iter:  19  accuracy:  0.5214285714285715\n",
            "iter:  20  accuracy:  0.5571428571428572\n",
            "iter:  21  accuracy:  0.5214285714285715\n",
            "iter:  22  accuracy:  0.6428571428571429\n",
            "iter:  23  accuracy:  0.6\n",
            "iter:  24  accuracy:  0.5785714285714286\n",
            "iter:  25  accuracy:  0.5357142857142857\n",
            "iter:  26  accuracy:  0.6\n",
            "iter:  27  accuracy:  0.5428571428571428\n",
            "iter:  28  accuracy:  0.6\n",
            "iter:  29  accuracy:  0.5928571428571429\n",
            "iter:  30  accuracy:  0.4785714285714286\n",
            "iter:  31  accuracy:  0.5714285714285714\n",
            "iter:  32  accuracy:  0.6285714285714286\n",
            "iter:  33  accuracy:  0.4642857142857143\n",
            "iter:  34  accuracy:  0.5857142857142857\n",
            "iter:  35  accuracy:  0.55\n",
            "iter:  36  accuracy:  0.5928571428571429\n",
            "iter:  37  accuracy:  0.5571428571428572\n",
            "iter:  38  accuracy:  0.5928571428571429\n",
            "iter:  39  accuracy:  0.5928571428571429\n",
            "iter:  40  accuracy:  0.5785714285714286\n",
            "iter:  41  accuracy:  0.5785714285714286\n",
            "iter:  42  accuracy:  0.5571428571428572\n",
            "iter:  43  accuracy:  0.5642857142857143\n",
            "iter:  44  accuracy:  0.6\n",
            "iter:  45  accuracy:  0.5\n",
            "iter:  46  accuracy:  0.55\n",
            "iter:  47  accuracy:  0.5285714285714286\n",
            "iter:  48  accuracy:  0.5785714285714286\n",
            "iter:  49  accuracy:  0.6\n",
            "iter:  50  accuracy:  0.55\n",
            "iter:  51  accuracy:  0.5714285714285714\n",
            "iter:  52  accuracy:  0.6285714285714286\n",
            "iter:  53  accuracy:  0.5142857142857142\n",
            "iter:  54  accuracy:  0.5857142857142857\n",
            "iter:  55  accuracy:  0.6142857142857143\n",
            "iter:  56  accuracy:  0.5857142857142857\n",
            "iter:  57  accuracy:  0.6071428571428571\n",
            "iter:  58  accuracy:  0.6142857142857143\n",
            "iter:  59  accuracy:  0.5857142857142857\n",
            "iter:  60  accuracy:  0.5642857142857143\n",
            "iter:  61  accuracy:  0.5285714285714286\n",
            "iter:  62  accuracy:  0.5642857142857143\n",
            "iter:  63  accuracy:  0.5928571428571429\n",
            "iter:  64  accuracy:  0.5071428571428571\n",
            "iter:  65  accuracy:  0.5928571428571429\n",
            "iter:  66  accuracy:  0.5714285714285714\n",
            "iter:  67  accuracy:  0.4928571428571429\n",
            "iter:  68  accuracy:  0.5285714285714286\n",
            "iter:  69  accuracy:  0.5928571428571429\n",
            "iter:  70  accuracy:  0.55\n",
            "iter:  71  accuracy:  0.5928571428571429\n",
            "iter:  72  accuracy:  0.5142857142857142\n",
            "iter:  73  accuracy:  0.6142857142857143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx7cMeYPFiEA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f97d60a-5d7e-4772-ae97-2a7790932de5"
      },
      "source": [
        "# now to finish the classification, take the aggregate of the results to \n",
        "# determine the classification\n",
        "\n",
        "classification = []\n",
        "\n",
        "for cell in range(len(y_test)):\n",
        "  preds = predictions[0][cell]\n",
        "\n",
        "  #get all the predictions for this cell\n",
        "  for pred in predictions[1:]:\n",
        "    preds = np.add(preds, pred[cell])\n",
        "  \n",
        "  # now take the index of the max value in the list\n",
        "  # this means that out of all the iterations, this\n",
        "  # was the most common prediction\n",
        "\n",
        "  classify = np.zeros(10)\n",
        "  max = np.max(preds)\n",
        "  index = list(preds).index(max)\n",
        "\n",
        "  classify[index] = 1\n",
        "\n",
        "  classification.append(classify)\n",
        "  \n",
        "\n",
        "# now from our final predictions, test the accuracy\n",
        "acc = accuracy_score(y_test, classification)\n",
        "\n",
        "print('final accuracy: ', acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "final accuracy:  0.8285714285714286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPRbOSHA_gFS"
      },
      "source": [
        "Write up:\n",
        "\n",
        "For this classification assignment, I decided to implement a BAGGING approach with a decision tree as my classifier. I decided to use a regular decision tree classifier model initially but found it hard to get the accuracy to be more than 61% even after playing around with the parameters. So I decided run multiple decision tree models and apply a BAGGING approach. By doing this, even if the individual parallel classifiers are not very good models, the aggregate of these classifiers will be much more robust. I also used a multiple output regressor on top of the classification tree since there are multiple classes/output. I also found that the classification tree performed better when the max_depth parameter was not set. For every iteration (with a maximum iteration limit of 100), I take a smaller sample of the training data and use that to train the model. If the accuracy of that model is more than or equal to 60%, I store the predictions. Because I'm using a BAGGING approach, a lower accuracy threshold for every iteration is okay in this case since I will be using the aggregate of the results anyway. After I have about 15 predictions with an accuaracy of at least 60%, I look through the prediction for every cell and take the most common prediction. In other words, I find the position of where the majority of the 1's are from all the stored predictions and use that as my final classification. With this impelementation that I just described, my final accuracy score is about 83%."
      ]
    }
  ]
}